{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will implement the Perceptron learning algorithm discussed in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing some libraries and examining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given an artificial dataset (iris.data) to study the perceptron learning algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set consists of 100 samples from each of two species of Iris (Iris Setosa and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "   Attributes\n",
    "- Sepal length: (cm)\n",
    "- Sepal width: (cm)\n",
    "- Petal length: (cm)\n",
    "- Petal width: (cm)\n",
    "\n",
    "\n",
    "\n",
    " Labels\n",
    "- setosa: -1\n",
    "- versicolor: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test our perceptron implementation, we will load the two flower classes Setosa and Versicolor from the Iris data set. The perceptron rule is not restricted to two dimensions, however, we will only consider the two features, sepal length and petal length, for visualization purposes.\n",
    "\n",
    "We extract the first feature column (sepal length) and the third feature column (petal length) of those 100 samples and assign them to X_train and X_test.\n",
    "\n",
    "The corresponding labels of X_train and X_test are stored in y_train and y_test, respectively, with 1 representing Versicolor and -1 representing Setosa.\n",
    " \n",
    "After running the code below, you will get:\n",
    "\n",
    "\n",
    "- X_train: 80 training samples with size (80, 2)\n",
    "- y_train: 80 training labels with size (80, )\n",
    "- X_test: 20 test samples with size (20, 2)\n",
    "- y_test: 20 test labels with size (20, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_iris():\n",
    "    df = pd.read_csv('iris.data', header=None, sep='\\s+| ',\n",
    "                       names=['c1','c2','c3','c4','y'], engine='python')\n",
    "\n",
    "    y = df.iloc[0:100, 4].values\n",
    "    \n",
    "    X = df.iloc[0:100, [0,2]].values\n",
    "    plt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label='setosa')\n",
    "    plt.scatter(X[50:100, 0], X[50:100, 1], color='blue', marker='x', label='versicolor')\n",
    "    plt.xlabel('petal length')\n",
    "    plt.ylabel('sepal length')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perceptron_data():\n",
    "    data = pd.read_csv('iris.data', header=None, sep='\\s+| ',\n",
    "                       names=['c1','c2','c3','c4','y'], engine='python').to_numpy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, X_test = data[:80, 0:4:2],data[80:, 0:4:2]\n",
    "    y_train, y_test = data[:80:, -1], data[80:, -1]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize via a two-dimensional scatter plot using the matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_perceptron_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate((X_train,X_test),axis=0)\n",
    "y_all = np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes how well your model performs using accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(pred, y_test):\n",
    "    return np.sum(y_test==pred)/y_test.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron has 2 hyperparameters that you can experiment with:\n",
    "- **Learning rate** - controls how much we change the current weights of the classifier during each update. We set it at a default value of 0.5, but you should experiment with different values. We recommend changing the learning rate by factors of 10 and observing how the performance of the classifier changes. You should also try adding a **decay** which slowly reduces the learning rate over each epoch.\n",
    "- **Number of Epochs** - An epoch is a complete iterative pass over all of the data in the dataset. During an epoch we predict a label using the classifier and then update the weights of the classifier according the perceptron update rule for each sample in the training set. You should try different values for the number of training epochs and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code: \n",
    "- The train function of the Perceptron class is trained on the training data.\n",
    "\n",
    "Training Algorithm:\n",
    "\n",
    "for each epcoh:<br />\n",
    "$\\quad$  for each training sample ($x^{n}$,$y^{n}$):<br />\n",
    "$\\quad$$\\quad$   $\\hat{y} = \\mathrm{sign}(w^Tx^n)$<br />\n",
    "$\\quad$$\\quad$   if $\\hat{y}$ != $y^{n}$:<br />\n",
    "$\\quad$$\\quad$$\\quad$Update weights and bias:<br />\n",
    "$\\quad$$\\quad$$\\quad$$\\quad$$  w_{t+1}  \\gets w_{t} +\\eta y^{n} x^{n}  $<br />\n",
    "$\\quad$$\\quad$$\\quad$$\\quad$$  b_{t+1}  \\gets b_{t} +\\eta y^{n} $<br />\n",
    "\n",
    "- We use the predict function to find the training accuracy as well as the testing accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialises Perceptron classifier with initializing \n",
    "weights, alpha(learning rate) and number of epochs.\n",
    "\"\"\"\n",
    "alpha = 0.5\n",
    "epochs = 100\n",
    "\n",
    "def predict(w, b, X_test):\n",
    "    \"\"\"\n",
    "    Predict labels for test data using the trained weights.\n",
    "\n",
    "    Inputs:\n",
    "    - X_test: A numpy array of shape (num_test, D) containing test data consisting\n",
    "         of num_test samples each of dimension D. Or a numpy array shape (D, ).\n",
    "\n",
    "    Returns:\n",
    "    - pred: A numpy array of shape (num_test, ) containing predicted labels for the\n",
    "      test data, where y[i] is the predicted label for the test point X[i].  Or a simple number. \n",
    "    \"\"\"\n",
    "    #\n",
    "    # your code here\n",
    "    #\n",
    "    return pred \n",
    "        \n",
    "def train(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train the Perceptron classifier. Use the perceptron update rule\n",
    "    as introduced in class.\n",
    "\n",
    "    Inputs:\n",
    "    - X_train: A numpy array of shape (num_train, D) containing the training data\n",
    "      consisting of num_train samples each of dimension D.\n",
    "    - y_train: A numpy array of shape (, ) containing the training labels, where\n",
    "         y[i] is the label for X[i].\n",
    "    \"\"\"\n",
    "    # weights : w with size (D, )\n",
    "    # bias : b is a constant\n",
    "    w = np.zeros([X_train.shape[1]])\n",
    "    b = 0\n",
    "    #    \n",
    "    # your code here\n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = predict(w, b, X_train)\n",
    "print('The training accuracy is given by : %f' % (get_acc(pred_percept, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_percept = predict(w, b, X_test)\n",
    "print('The testing accuracy is given by : %f' % (get_acc(pred_percept, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the decision boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the decision boundaries for our dataset, let's implement a small convenience function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_regions(w, b, X, y, resolution=0.02):\n",
    "   \n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x' )\n",
    "    colors = ('red', 'blue')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    \n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    \n",
    "    Z = predict(w, b, np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "  \n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    \n",
    "    \n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        a = y==cl\n",
    "        plt.scatter(x=X[a, 0], y=X[a, 1],\n",
    "                    alpha=0.8, c=cmap(idx),\n",
    "                    marker=markers[idx], label=cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(w, b, X_all, y_all)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
